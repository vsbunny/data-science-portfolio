{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a231b6-885d-48a5-abb9-e81faec70bb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd # Import pandas for data manipulation and DataFrame operations\n",
    "import glob # Import glob for finding files matching a pattern (e.g., all CSVs in a directory)\n",
    "import os # Import os for operating system-related functionalities (e.g., path manipulation)\n",
    "\n",
    "# --- Configuration ---\n",
    "# Define the path to the directory containing the extracted CSV files from the scraper.\n",
    "# It's assumed these CSVs are the raw output from the QS World Rankings scraper.\n",
    "# IMPORTANT: Replace 'path to extracted csv files' with the actual relative or absolute path\n",
    "path = '/Scraping_projects/QS_world_rankings'\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8c2907-8476-4c7d-9c40-23652844af0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "# Define the path to the directory containing your raw extracted CSV files.\n",
    "# This path is relative to where this script (process_rankings.py) is located.\n",
    "# Assumed structure: .../QS_world_rankings/QS World Rankings/\n",
    "CSV_INPUT_FOLDER = 'rankings_csv'\n",
    "\n",
    "# Define the output folder for the combined and processed CSVs.\n",
    "# This folder will be created within the same directory as this script.\n",
    "COMBINED_OUTPUT_FOLDER = 'Combined_Rankings'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(COMBINED_OUTPUT_FOLDER):\n",
    "    os.makedirs(COMBINED_OUTPUT_FOLDER)\n",
    "    print(f\"Created output directory for combined CSVs: {COMBINED_OUTPUT_FOLDER}\")\n",
    "\n",
    "\n",
    "# --- Define the mapping for Child Subject to Parent Subject ---\n",
    "# This dictionary maps specific child subject strings (extracted from filenames)\n",
    "# to their broader parent subject categories. This helps standardize the data.\n",
    "# IMPORTANT: This map contains only a subset for demonstration. It is needed to\n",
    "# populate this dictionary with ALL the relevant child subjects and their\n",
    "# corresponding parent categories if you expand the scraping.\n",
    "subject_to_parent_map = {\n",
    "    \"theology-divinity-religious-studies\": \"Arts & Humanities\",\n",
    "    #\"veterinary-science\": \"Life Sciences & Medicine\",\n",
    "    #\"computer-science\": \"Engineering & Technology\",\n",
    "    #\"physics-astronomy\": \"Natural Sciences\",\n",
    "    \"economics-econometrics\": \"Social Sciences & Management\",\n",
    "    \"accounting-finance\": \"Social Sciences & Management\",\n",
    "    \"business-management-studies\": \"Social Sciences & Management\",\n",
    "    \"arts-and-humanities\": \"Arts & Humanities\",\n",
    "    \"archaeology\" : \"Arts & Humanities\", \n",
    "    #\"life-sciences-medicine\": \"Life Sciences & Medicine\",\n",
    "    #\"natural-sciences\": \"Natural Sciences\",\n",
    "    #\"social-sciences-management\": \"Social Sciences & Management\",\n",
    "    # Add the rest of the child subjects and their parent categories here as needed:\n",
    "    # \"mathematics\": \"Natural Sciences\",\n",
    "     \"history\": \"Arts & Humanities\",\n",
    "    # ... and so on for all subjects the scraper might extract.\n",
    "}\n",
    "print(\"Subject-to-Parent mapping defined (partial for demonstration).\")\n",
    "\n",
    "# --- File Discovery ---\n",
    "# Use glob to find all files ending with '.csv' within the specified input folder.\n",
    "# os.path.join ensures cross-platform compatibility when constructing paths.\n",
    "all_files = glob.glob(os.path.join(CSV_INPUT_FOLDER, \"*.csv\"))\n",
    "print(f\"Found CSV files: {all_files}\")\n",
    "\n",
    "# Use a dictionary to store DataFrames, organized by year.\n",
    "# This structure facilitates combining all subject-specific CSVs for a given year.\n",
    "dfs_by_year = {}\n",
    "\n",
    "# --- Process Each CSV File ---\n",
    "# Iterate through each found CSV file to read, clean, and standardize its data.\n",
    "for filepath in all_files:\n",
    "    try:\n",
    "        # Extract only the filename from the full path (e.g., 'QS_Rankings_subject-name-year.csv').\n",
    "        filename = os.path.basename(filepath)\n",
    "        print(f\"\\nProcessing file: {filename}\")\n",
    "\n",
    "        # Split the filename by underscores to parse out components.\n",
    "        # Assumed filename format: 'QS_Rankings_SUBJECT-YEAR.csv'\n",
    "        parts = filename.split('_')\n",
    "        # Extract the subject and year from the last part of the filename.\n",
    "        # .split('.')[0] removes the '.csv' extension.\n",
    "        # .rsplit('-', 1) splits from the right, only once, to separate the subject name from the year.\n",
    "        subject_and_year = parts[-1].split('.')[0]\n",
    "        subject, year = subject_and_year.rsplit('-', 1)\n",
    "\n",
    "        # Read the CSV file into a Pandas DataFrame.\n",
    "        df = pd.read_csv(filepath)\n",
    "        print(f\"DataFrame loaded. Original columns: {df.columns.tolist()}\")\n",
    "\n",
    "        # --- Data Standardization and Feature Addition Logic ---\n",
    "        # This section handles variations in the raw scraped data (e.g., missing 'Global Engagement' column)\n",
    "        # and adds new categorical features ('Year', 'Parent Subject', 'Child Subject') to standardize the dataset.\n",
    "\n",
    "        # 1. Ensure 'Global Engagement' column exists for consistent schema.\n",
    "        if 'Global Engagement' not in df.columns:\n",
    "            # If 'Global Engagement' is NOT present, add it as an empty column.\n",
    "            # This accounts for variations in data provided by the website for certain subjects/years.\n",
    "            df['Global Engagement'] = '' # Initialize with empty strings\n",
    "            print(\"Added 'Global Engagement' column (was missing in this file).\")\n",
    "\n",
    "        # Dynamically assign 'Parent Subject' using the pre-defined mapping dictionary.\n",
    "        # .get(key, default_value) provides a robust lookup, returning \"Uncategorized\" if a subject is not mapped.\n",
    "        parent_subject_category = subject_to_parent_map.get(subject, \"Uncategorized\")\n",
    "        print(f\"Assigned Parent Subject: '{parent_subject_category}' for Child Subject: '{subject}'\")\n",
    "\n",
    "        # Determine the insertion index for new columns to maintain consistent order.\n",
    "        # Defaults to -1 (end of DataFrame) if 'Global Engagement' column is not found (though it should be handled above).\n",
    "        global_engagement_index = -1\n",
    "        if 'Global Engagement' in df.columns:\n",
    "            global_engagement_index = df.columns.get_loc('Global Engagement')\n",
    "\n",
    "        # Insert 'Year', 'Parent Subject', and 'Child Subject' columns into the DataFrame.\n",
    "        # These are inserted relative to the 'Global Engagement' column for standardized placement.\n",
    "        df.insert(global_engagement_index + 1, 'Year', year)\n",
    "        df.insert(global_engagement_index + 2, 'Parent Subject', parent_subject_category)\n",
    "        df.insert(global_engagement_index + 3, 'Child Subject', subject)\n",
    "        print(\"Inserted 'Year', 'Parent Subject', 'Child Subject' columns.\")\n",
    "\n",
    "\n",
    "        # --- Grouping DataFrames by Year ---\n",
    "        # Store the processed DataFrame in the 'dfs_by_year' dictionary, grouped by its 'year'.\n",
    "        if year not in dfs_by_year:\n",
    "            dfs_by_year[year] = [] # Initialize a list for the year if it's encountered for the first time\n",
    "        dfs_by_year[year].append(df) # Add the processed DataFrame to the list for its respective year\n",
    "\n",
    "    except ValueError as e:\n",
    "        # Catch ValueError, which might occur if filename parsing fails due to an unexpected format.\n",
    "        print(f\"Skipping file with unexpected name or format: {filepath}. Error: {e}\")\n",
    "        continue # Continue processing the next file in the list\n",
    "    except KeyError as e:\n",
    "        # Catch KeyError if a 'child subject' extracted from the filename is not found in the 'subject_to_parent_map'.\n",
    "        print(f\"Skipping file: '{filepath}'. Child subject '{subject}' not found in mapping. Error: {e}\")\n",
    "        continue # Continue processing the next file\n",
    "\n",
    "# --- Combine and Save DataFrames by Year ---\n",
    "# After processing all individual CSVs, this section combines them into a single DataFrame for each year.\n",
    "# This creates a consolidated dataset per year, ready for further analysis or model training.\n",
    "print(\"\\nCombining and saving data by year...\")\n",
    "for year, dfs in dfs_by_year.items():\n",
    "    # Concatenate all DataFrames for the current year into a single DataFrame.\n",
    "    # ignore_index=True resets the index of the combined DataFrame, preventing duplicate indices.\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # --- Optional: Reorder columns for final output consistency ---\n",
    "    # This ensures a standardized column order across all combined CSVs, which is beneficial for\n",
    "    # subsequent analysis and readability. Adjust 'desired_order' to your preferred final sequence.\n",
    "    desired_order = [\n",
    "        'Rank', 'Name', 'Location', 'Parent Subject', 'Child Subject', 'Year',\n",
    "        'Employer Reputation', 'H-index Citations', 'Citations per Paper',\n",
    "        'Academic Reputation', 'Global Engagement'\n",
    "    ]\n",
    "    # Filter and reorder columns, adding any new columns found in 'combined_df' that aren't in 'desired_order'\n",
    "    # (these remaining columns will be appended at the end, sorted alphabetically).\n",
    "    final_columns = [col for col in desired_order if col in combined_df.columns]\n",
    "    remaining_columns = [col for col in combined_df.columns if col not in set(final_columns)]\n",
    "    combined_df = combined_df[final_columns + sorted(remaining_columns)] # Reorder and append sorted remaining columns\n",
    "\n",
    "\n",
    "    # Save the combined DataFrame for the year to a new CSV file.\n",
    "    # The output file is placed in the 'COMBINED_OUTPUT_FOLDER' (e.g., './Combined_Rankings/').\n",
    "    # index=False prevents pandas from writing the DataFrame index as a column in the CSV.\n",
    "    output_filename = f'QS_Rankings_Combined_{year}.csv'\n",
    "    output_filepath = os.path.join(COMBINED_OUTPUT_FOLDER, output_filename)\n",
    "    combined_df.to_csv(output_filepath, index=False)\n",
    "    print(f\"Saved combined data for {year} to: {output_filepath}\")\n",
    "\n",
    "print(\"\\nData wrangling complete. Combined CSVs are in the 'Combined_Rankings' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ce11bf-baf4-4667-9351-9cebe2eaa228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
